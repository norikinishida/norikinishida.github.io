{
    "root": [
        {
            "id": 0,
            "parent": -1,
            "text": "ROOT",
            "relation": "null"
        },
        {
            "id": 1,
            "parent": 3,
            "text": "There has been an explosion of work in the vision & language community during the past few years from image captioning to video transcription , and answering questions about images . <S>",
            "relation": "CONTRAST"
        },
        {
            "id": 2,
            "parent": 1,
            "text": "These tasks have focused on literal descriptions of the image . <S>",
            "relation": "ELABORATION"
        },
        {
            "id": 3,
            "parent": 7,
            "text": "To move beyond the literal , ",
            "relation": "BACKGROUND"
        },
        {
            "id": 4,
            "parent": 5,
            "text": "we choose to explore ",
            "relation": "ATTRIBUTION"
        },
        {
            "id": 5,
            "parent": 3,
            "text": "how questions about an image are often directed at commonsense inference and the abstract events ",
            "relation": "ENABLEMENT"
        },
        {
            "id": 6,
            "parent": 5,
            "text": "evoked by objects in the image . <S>",
            "relation": "ELABORATION"
        },
        {
            "id": 7,
            "parent": 0,
            "text": "In this paper , we introduce the novel task of Visual Question Generation ( VQG ) , ",
            "relation": "ROOT"
        },
        {
            "id": 8,
            "parent": 7,
            "text": "where the system is tasked ",
            "relation": "ELABORATION"
        },
        {
            "id": 9,
            "parent": 8,
            "text": "with asking a natural and engaging question ",
            "relation": "MANNER-MEANS"
        },
        {
            "id": 10,
            "parent": 9,
            "text": "when shown an image . <S>",
            "relation": "CONDITION"
        },
        {
            "id": 11,
            "parent": 7,
            "text": "We provide three datasets ",
            "relation": "ELABORATION"
        },
        {
            "id": 12,
            "parent": 11,
            "text": "which cover a variety of images from object-centric to event-centric , with considerably more abstract training data ",
            "relation": "ELABORATION"
        },
        {
            "id": 13,
            "parent": 12,
            "text": "than provided to state-of-the-art captioning systems thus far . <S>",
            "relation": "COMPARISON"
        },
        {
            "id": 14,
            "parent": 7,
            "text": "We train and test several generative and retrieval models ",
            "relation": "ELABORATION"
        },
        {
            "id": 15,
            "parent": 14,
            "text": "to tackle the task of VQG . <S>",
            "relation": "ENABLEMENT"
        },
        {
            "id": 16,
            "parent": 18,
            "text": "Evaluation results show ",
            "relation": "ATTRIBUTION"
        },
        {
            "id": 17,
            "parent": 18,
            "text": "that while such models ask reasonable questions for a variety of images , ",
            "relation": "CONDITION"
        },
        {
            "id": 18,
            "parent": 7,
            "text": "there is still a wide gap with human performance ",
            "relation": "EVALUATION"
        },
        {
            "id": 19,
            "parent": 18,
            "text": "which motivates further work ",
            "relation": "ELABORATION"
        },
        {
            "id": 20,
            "parent": 19,
            "text": "on connecting images with commonsense knowledge and pragmatics . <S>",
            "relation": "ELABORATION"
        },
        {
            "id": 21,
            "parent": 7,
            "text": "Our proposed task offers a new challenge to the community ",
            "relation": "EVALUATION"
        },
        {
            "id": 22,
            "parent": 21,
            "text": "which we hope furthers interest ",
            "relation": "ELABORATION"
        },
        {
            "id": 23,
            "parent": 22,
            "text": "in exploring deeper connections between vision & language . <S>",
            "relation": "ELABORATION"
        }
    ]
}