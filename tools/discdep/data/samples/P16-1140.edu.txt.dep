{
    "root": [
        {
            "id": 0,
            "parent": -1,
            "text": "ROOT",
            "relation": "null"
        },
        {
            "id": 1,
            "parent": 2,
            "text": "Recently , many NLP tasks have benefited from distributed word representation . <S>",
            "relation": "CONTRAST"
        },
        {
            "id": 2,
            "parent": 5,
            "text": "However , it remains unknown ",
            "relation": "BACKGROUND"
        },
        {
            "id": 3,
            "parent": 2,
            "text": "whether embedding models are really immune to the typological diversity of languages , ",
            "relation": "ELABORATION"
        },
        {
            "id": 4,
            "parent": 3,
            "text": "despite the language-independent architecture . <S>",
            "relation": "CONTRAST"
        },
        {
            "id": 5,
            "parent": 0,
            "text": "Here we investigate three representative models on a large set of language samples ",
            "relation": "ROOT"
        },
        {
            "id": 6,
            "parent": 5,
            "text": "by mapping dense embedding to sparse linguistic property space . <S>",
            "relation": "MANNER-MEANS"
        },
        {
            "id": 7,
            "parent": 5,
            "text": "Experiment results reveal the language universal and specific properties ",
            "relation": "EVALUATION"
        },
        {
            "id": 8,
            "parent": 7,
            "text": "encoded in various word representation . <S>",
            "relation": "ELABORATION"
        },
        {
            "id": 9,
            "parent": 5,
            "text": "Additionally , strong evidence supports the utility of word form , especially for inflectional languages . <S>",
            "relation": "EVALUATION"
        }
    ]
}