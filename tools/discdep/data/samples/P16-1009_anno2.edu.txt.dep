{
    "root": [
        {
            "id": 0,
            "parent": -1,
            "text": "ROOT",
            "relation": "null"
        },
        {
            "id": 1,
            "parent": 5,
            "text": "Neural Machine Translation ( NMT ) has obtained state-of-the art performance for several language pairs , ",
            "relation": "BACKGROUND"
        },
        {
            "id": 2,
            "parent": 1,
            "text": "while only using parallel data for training . <S>",
            "relation": "CONDITION"
        },
        {
            "id": 3,
            "parent": 5,
            "text": "Targetside monolingual data plays an important role ",
            "relation": "CAUSE-RESULT-REASON"
        },
        {
            "id": 4,
            "parent": 3,
            "text": "in boosting fluency for phrasebased statistical machine translation , ",
            "relation": "ELABORATION"
        },
        {
            "id": 5,
            "parent": 0,
            "text": "and we investigate the use of monolingual data for NMT . <S>",
            "relation": "ROOT"
        },
        {
            "id": 6,
            "parent": 9,
            "text": "In contrast to previous work , ",
            "relation": "CONTRAST"
        },
        {
            "id": 7,
            "parent": 6,
            "text": "which combines NMT models with separately trained language models , ",
            "relation": "ELABORATION"
        },
        {
            "id": 8,
            "parent": 9,
            "text": "we note ",
            "relation": "ATTRIBUTION"
        },
        {
            "id": 9,
            "parent": 5,
            "text": "that encoder-decoder NMT architectures already have the capacity ",
            "relation": "ELABORATION"
        },
        {
            "id": 10,
            "parent": 9,
            "text": "to learn the same information as a language model , ",
            "relation": "ENABLEMENT"
        },
        {
            "id": 11,
            "parent": 8,
            "text": "and we explore strategies ",
            "relation": "JOINT"
        },
        {
            "id": 12,
            "parent": 11,
            "text": "to train with monolingual data ",
            "relation": "ENABLEMENT"
        },
        {
            "id": 13,
            "parent": 12,
            "text": "without changing the neural network architecture . <S>",
            "relation": "ELABORATION"
        },
        {
            "id": 14,
            "parent": 15,
            "text": "By pairing monolingual training data with an automatic backtranslation , ",
            "relation": "MANNER-MEANS"
        },
        {
            "id": 15,
            "parent": 16,
            "text": "we can treat it as additional parallel training data , ",
            "relation": "ELABORATION"
        },
        {
            "id": 16,
            "parent": 5,
            "text": "and we obtain substantial improvements on the WMT 15 task English to German ( +2.8-3.7 BLEU ) , and for the low-resourced IWSLT 14 task Turkish to English ( +2.1-3.4 BLEU ) , ",
            "relation": "EVALUATION"
        },
        {
            "id": 17,
            "parent": 16,
            "text": "obtaining new state-of-the-art results . <S>",
            "relation": "ELABORATION"
        },
        {
            "id": 18,
            "parent": 19,
            "text": "We also show ",
            "relation": "ATTRIBUTION"
        },
        {
            "id": 19,
            "parent": 5,
            "text": "that fine-tuning on in-domain monolingual and parallel data gives substantial improvements for the IWSLT 15 task English ! German . <S>",
            "relation": "EVALUATION"
        }
    ]
}