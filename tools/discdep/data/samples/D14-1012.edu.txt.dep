{
    "root": [
        {
            "id": 0,
            "parent": -1,
            "text": "ROOT",
            "relation": "null"
        },
        {
            "id": 1,
            "parent": 7,
            "text": "Recent work has shown success ",
            "relation": "CAUSE-RESULT-REASON"
        },
        {
            "id": 2,
            "parent": 1,
            "text": "in using continuous word embeddings ",
            "relation": "ELABORATION"
        },
        {
            "id": 3,
            "parent": 2,
            "text": "learned from unlabeled data ",
            "relation": "ELABORATION"
        },
        {
            "id": 4,
            "parent": 3,
            "text": "as features ",
            "relation": "COMPARISON"
        },
        {
            "id": 5,
            "parent": 2,
            "text": "to improve supervised NLP systems , ",
            "relation": "ENABLEMENT"
        },
        {
            "id": 6,
            "parent": 5,
            "text": "which is regarded as a simple semi-supervised learning mechanism . <S>",
            "relation": "ELABORATION"
        },
        {
            "id": 7,
            "parent": 10,
            "text": "However , fundamental problems ",
            "relation": "BACKGROUND"
        },
        {
            "id": 8,
            "parent": 7,
            "text": "on effectively incorporating the word embedding features within the framework of linear models ",
            "relation": "ELABORATION"
        },
        {
            "id": 9,
            "parent": 7,
            "text": "remain . <S>",
            "relation": "SAME-UNIT"
        },
        {
            "id": 10,
            "parent": 0,
            "text": "In this study , we investigate and analyze three different approaches , ",
            "relation": "ROOT"
        },
        {
            "id": 11,
            "parent": 10,
            "text": "including a new proposed distributional prototype approach , ",
            "relation": "EXEMPLIFICATION"
        },
        {
            "id": 12,
            "parent": 11,
            "text": "for utilizing the embedding features . <S>",
            "relation": "ENABLEMENT"
        },
        {
            "id": 13,
            "parent": 10,
            "text": "The presented approaches can be integrated into most of the classical linear models in NLP . <S>",
            "relation": "ELABORATION"
        },
        {
            "id": 14,
            "parent": 15,
            "text": "Experiments on the task of named entity recognition show ",
            "relation": "MANNER-MEANS"
        },
        {
            "id": 15,
            "parent": 10,
            "text": "that each of the proposed approaches can better utilize the word embedding features , ",
            "relation": "EVALUATION"
        },
        {
            "id": 16,
            "parent": 15,
            "text": "among which the distributional prototype approach performs the best . <S>",
            "relation": "COMPARISON"
        },
        {
            "id": 17,
            "parent": 15,
            "text": "Moreover , the combination of the approaches provides additive improvements , ",
            "relation": "ELABORATION"
        },
        {
            "id": 18,
            "parent": 17,
            "text": "outperforming the dense and continuous embedding features by nearly 2 points of F1 score . <S>",
            "relation": "ELABORATION"
        }
    ]
}