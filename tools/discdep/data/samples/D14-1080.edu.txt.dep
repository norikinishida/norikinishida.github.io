{
    "root": [
        {
            "id": 0,
            "parent": -1,
            "text": "ROOT",
            "relation": "null"
        },
        {
            "id": 1,
            "parent": -1,
            "text": "Recurrent neural networks ( RNNs ) are connectionist models of sequential data ",
            "relation": "null"
        },
        {
            "id": 2,
            "parent": 1,
            "text": "that are naturally applicable to the analysis of natural language . <S>",
            "relation": "ELABORATION"
        },
        {
            "id": 3,
            "parent": 1,
            "text": "Recently , \"depth in space\" \u2014 as an orthogonal notion to \"depth in time\" \u2014 in RNNs has been investigated ",
            "relation": "ELABORATION"
        },
        {
            "id": 4,
            "parent": 3,
            "text": "by stacking multiple layers of RNNs ",
            "relation": "ELABORATION"
        },
        {
            "id": 5,
            "parent": 3,
            "text": "and shown empirically to bring a temporal hierarchy to the architecture . <S>",
            "relation": "JOINT"
        },
        {
            "id": 6,
            "parent": 0,
            "text": "In this work we apply these deep RNNs to the task of opinion expression extraction ",
            "relation": "ROOT"
        },
        {
            "id": 7,
            "parent": 6,
            "text": "formulated as a token-level sequence-labeling task . <S>",
            "relation": "ELABORATION"
        },
        {
            "id": 8,
            "parent": 9,
            "text": "Experimental results show ",
            "relation": "ATTRIBUTION"
        },
        {
            "id": 9,
            "parent": 6,
            "text": "that deep , narrow RNNs outperform traditional shallow , wide RNNs with the same number of parameters . <S>",
            "relation": "EVALUATION"
        },
        {
            "id": 10,
            "parent": 9,
            "text": "Furthermore , our approach outperforms previous CRF-based baselines , ",
            "relation": "ELABORATION"
        },
        {
            "id": 11,
            "parent": 10,
            "text": "including the state-of-the-art semi-Markov CRF model , ",
            "relation": "ELABORATION"
        },
        {
            "id": 12,
            "parent": 10,
            "text": "and does so ",
            "relation": "JOINT"
        },
        {
            "id": 13,
            "parent": 12,
            "text": "without access to the powerful opinion lexicons and syntactic features ",
            "relation": "ELABORATION"
        },
        {
            "id": 14,
            "parent": 13,
            "text": "relied upon by the semi-CRF , ",
            "relation": "ELABORATION"
        },
        {
            "id": 15,
            "parent": 13,
            "text": "as well as without the standard layer-by-layer pre-training ",
            "relation": "JOINT"
        },
        {
            "id": 16,
            "parent": 15,
            "text": "typically required of RNN architectures . <S>",
            "relation": "ELABORATION"
        }
    ]
}