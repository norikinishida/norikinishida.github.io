{
    "root": [
        {
            "id": 0,
            "parent": -1,
            "text": "ROOT",
            "relation": "null"
        },
        {
            "id": 1,
            "parent": 0,
            "text": "We present a method \r",
            "relation": "ROOT"
        },
        {
            "id": 2,
            "parent": 1,
            "text": "that learns word embedding for Twitter sentiment classification in this paper . <S>\r",
            "relation": "ELABORATION"
        },
        {
            "id": 3,
            "parent": 4,
            "text": "Most existing algorithms for learning continuous word representations typically only model the syntactic context of words \r",
            "relation": "CONTRAST"
        },
        {
            "id": 4,
            "parent": 1,
            "text": "but ignore the sentiment of text . <S>\r",
            "relation": "BACKGROUND"
        },
        {
            "id": 5,
            "parent": 4,
            "text": "This is problematic for sentiment analysis \r",
            "relation": "ELABORATION"
        },
        {
            "id": 6,
            "parent": 5,
            "text": "as they usually map words with similar syntactic context but opposite sentiment polarity , such as good and bad , to neighboring word vectors . <S>\r",
            "relation": "CAUSE-RESULT-REASON"
        },
        {
            "id": 7,
            "parent": 1,
            "text": "We address this issue \r",
            "relation": "ELABORATION"
        },
        {
            "id": 8,
            "parent": 7,
            "text": "by learning sentiment-specific word embedding ( SSWE ) , \r",
            "relation": "MANNER-MEANS"
        },
        {
            "id": 9,
            "parent": 8,
            "text": "which encodes sentiment information in the continuous representation of words . <S>\r",
            "relation": "ELABORATION"
        },
        {
            "id": 10,
            "parent": 7,
            "text": "Specifically , we develop three neural networks \r",
            "relation": "ELABORATION"
        },
        {
            "id": 11,
            "parent": 10,
            "text": "to effectively incorporate the supervision from sentiment polarity of text \r",
            "relation": "ENABLEMENT"
        },
        {
            "id": 12,
            "parent": 11,
            "text": "( e.g. sentences or tweets ) \r",
            "relation": "EXEMPLIFICATION"
        },
        {
            "id": 13,
            "parent": 11,
            "text": "in their loss functions . <S>\r",
            "relation": "SAME-UNIT"
        },
        {
            "id": 14,
            "parent": 15,
            "text": "To obtain large scale training corpora , \r",
            "relation": "ENABLEMENT"
        },
        {
            "id": 15,
            "parent": 1,
            "text": "we learn the sentiment-specific word embedding from massive distant-supervised tweets \r",
            "relation": "ELABORATION"
        },
        {
            "id": 16,
            "parent": 15,
            "text": "collected by positive and negative emoticons . <S>\r",
            "relation": "ELABORATION"
        },
        {
            "id": 17,
            "parent": 18,
            "text": "Experiments on applying SSWE to a benchmark Twitter sentiment classification dataset in SemEval 2013 show \r",
            "relation": "ATTRIBUTION"
        },
        {
            "id": 18,
            "parent": 1,
            "text": "that ( 1 ) the SSWE feature performs comparably with hand-crafted features in the top-performed system \r",
            "relation": "EVALUATION"
        },
        {
            "id": 19,
            "parent": 18,
            "text": "; ( 2 ) the performance is further improved \r",
            "relation": "JOINT"
        },
        {
            "id": 20,
            "parent": 19,
            "text": "by concatenating SSWE with existing feature set . <S>\r",
            "relation": "MANNER-MEANS"
        }
    ]
}