{
    "root": [
        {
            "id": 0,
            "parent": -1,
            "text": "ROOT",
            "relation": "null"
        },
        {
            "id": 1,
            "parent": 2,
            "text": "We prove ",
            "relation": "ATTRIBUTION"
        },
        {
            "id": 2,
            "parent": 0,
            "text": "that log-linearly interpolated backoff language models can be efficiently and exactly collapsed into a single normalized backoff model , ",
            "relation": "ROOT"
        },
        {
            "id": 3,
            "parent": 2,
            "text": "contradicting Hsu ( 2007 ) . <S>",
            "relation": "CONTRAST"
        },
        {
            "id": 4,
            "parent": 5,
            "text": "While prior work reported ",
            "relation": "ATTRIBUTION"
        },
        {
            "id": 5,
            "parent": 6,
            "text": "that log-linear interpolation yields lower perplexity than linear interpolation , ",
            "relation": "CONTRAST"
        },
        {
            "id": 6,
            "parent": 7,
            "text": "normalizing at query time was impractical . <S>",
            "relation": "CAUSE-RESULT-REASON"
        },
        {
            "id": 7,
            "parent": 2,
            "text": "We normalize the model offline in advance , ",
            "relation": "ELABORATION"
        },
        {
            "id": 8,
            "parent": 7,
            "text": "which is efficient due to a ecurrence relationship between the normalizing factors . <S>",
            "relation": "ELABORATION"
        },
        {
            "id": 9,
            "parent": 10,
            "text": "To tune interpolation weights , ",
            "relation": "ENABLEMENT"
        },
        {
            "id": 10,
            "parent": 2,
            "text": "we apply Newton 's method to this convex problem ",
            "relation": "ELABORATION"
        },
        {
            "id": 11,
            "parent": 12,
            "text": "and show ",
            "relation": "ATTRIBUTION"
        },
        {
            "id": 12,
            "parent": 10,
            "text": "that the derivatives can be computed efficiently in a batch process . <S>",
            "relation": "ELABORATION"
        },
        {
            "id": 13,
            "parent": 12,
            "text": "These findings are combined in new open-source interpolation tool , ",
            "relation": "ELABORATION"
        },
        {
            "id": 14,
            "parent": 13,
            "text": "which is distributed with KenLM . <S>",
            "relation": "ELABORATION"
        },
        {
            "id": 15,
            "parent": 2,
            "text": "With 21 out-of-domain corpora , log-linear interpolation yields 72.58 perplexity on TED talks , ",
            "relation": "EVALUATION"
        },
        {
            "id": 16,
            "parent": 15,
            "text": "compared to 75.91 for linear interpolation . <S>    ",
            "relation": "COMPARISON"
        }
    ]
}